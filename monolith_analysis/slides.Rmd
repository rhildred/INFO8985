---
title: Monolith (analysis - midterm review)
lab: https://github.com/rhildred/info8985_monolith_analysis
---
## Agenda

- Review instrumentation from [last week](`r rmarkdown::metadata$lab`) for assignment 1
- Review the learning outcomes for the midterm
- Work period on assignment 1

Based on chapter 1-5 in text and notes summarized here.

## The midterm is 4 written response questions

- in the quiz tool
- each question is worth 5 marks
- each question is based on a situation

## Covered Learning outcomes

- Test monolith and microservice architectures for observability and resolve deficiencies using tracing, metrics and logging.
- Support development and operations by separating exception tracing from exception handling.
- Prioritize deviations from metric baselines by sending and responding to alerts
- Justify issue priority based on evidence from monitoring and logging.

## Test for deficiencies

- A dev-ops team would ultimately write a failing test that exposes the root cause of a system outage, make the test pass and deploy through continuous integration.
- Monitoring and logging helps get to the root cause of a problem a customer may be facing
- In chapter 4 of the book, we looked at different things we can learn from the otel demo
- correlate what the customer is seeing with metrics ... for instance

## Relate REDS metrics to what the customer is seeing

- use metric attributes to drill down to the subsystem
- compare REDS metrics to what the customer is seeing
- errors for instance will be above the baseline established previously if customers are seeing errors

## Separate tracing from handling

```python
from opentelemetry import trace
span = trace.get_current_span()
except ValueError as exc:
    # Record the exception and update the span status.
    span.record_exception(exc)
    span.set_status(trace.Status(trace.StatusCode.ERROR, str(exc)))
    raise
```

## Separate logging from handling

```python
import traceback
import logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)
try:
    do_something_that_might_error()
except Exception as error:
    logger.debug(traceback.format_exc())
    raise
```

## Separate Metric from handling

```python
try:
    do_something_that_might_error()
except:
    error_counter.add(1, {"error.module": __name__})
    raise
```

## Always remember to raise

```python
except ValueError as exc:
    ...
    raise
```
- critical so that the calling app can deal with the exception


## Metric baselines

## Supporting Evidence
